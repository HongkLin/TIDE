<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="UniSeg3D">
  <meta name="keywords" content="Point Cloud Segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TIDE</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">



  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


</head>
<body>


<script src="../../assets/js/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
    backgroundColor: '#fff',
    innerHTML: 'Back to Top',
    textColor: '#333'
  })
</script>
<style>
    #back-to-top {
      border: 1px solid #ccc;
      border-radius: 0;
      font-size: 15px;
      width: 100px;
      text-align: center;
      line-height: 30px;
      height: 30px;
    }
</style>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Unified Image-Dense Annotation Generation Model for Underwater Scenes</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/HongkLin?tab=repositories" target="_blank" rel="noopener noreferrer">Hongkai Lin</a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Tre69v0AAAAJ&hl=zh-CN" target="_blank" rel="noopener noreferrer">Dingkang Liang</a>,</span>
            <span class="author-block">
              <a href=" " target="_blank" rel="noopener noreferrer">Zhenghao Qi</a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=UeltiQ4AAAAJ&hl=zh-CN" target="_blank" rel="noopener noreferrer">Xiang Bai</a><sup>†</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Huazhong University of Science & Technology</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>†</sup> Corresponding author.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.21771"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/HongkLin/TIDE"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="column is-center has-text-centered">
            <img src="./static/images/visualization.png"
                 class="interpolation-image"/>
        </div>
        <br/>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Underwater dense prediction, especially depth estimation and semantic segmentation, is crucial for comprehensively understanding underwater scenes.
          Nevertheless, high-quality and large-scale underwater datasets with dense annotations remain scarce because of the complex environment and the exorbitant data collection costs.
          This paper proposes a unified <strong>T</strong>ext-to-<strong>I</strong>mage and <strong>DE</strong>nse annotation generation method (TIDE) for underwater scenes.
          It relies solely on text as input to simultaneously generate realistic underwater images and multiple highly consistent dense annotations.
          Specifically, we unify the generation of text-to-image and text-to-dense annotations within a single model.
          The <strong>I</strong>mplicit <strong>L</strong>ayout <strong>S</strong>haring mechanism (ILS) and cross-modal interaction method called <strong>T</strong>ime <strong>A</strong>daptive <strong>N</strong>ormalization (TAN) are introduced to jointly optimize the consistency between image and dense annotations.
          We synthesize a large underwater dataset using TIDE to validate the effectiveness of our method in underwater dense prediction tasks.
          The results demonstrate that our method effectively improves the performance of existing underwater dense prediction models and mitigates the scarcity of underwater data with dense annotations.
          Our method can offer new perspectives on alleviating data scarcity issues in other fields.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Overview</h2>
      <div class="item" style="text-align: center;">
        <img src="./static/images/introduction.png" alt="MY ALT TEXT" style="width: auto; height: 500px;"/>
        <div class="content has-text-justified">
          <p>
            In this work, to address the scarcity of large-scale, high-quality underwater datasets with dense annotations,
            we explore a novel framework that simultaneously generates images and multiple dense annotations solely based on text conditions.
            By leveraging the inherent implicit layout information and cross-modal features in text-to-image models, we develop an interaction mechanism to align images and dense annotations.
            Experimental results show that this interaction mechanism achieves comparable or even better consistency than controllable generation methods requiring strong guidance conditions (such as depth maps).
          </p>
        </div>
  </div>
</div>
</div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Pipeline</h2>
      <div class="item">
        <img src="static/images/pipeline.png" alt="MY ALT TEXT"/>
        <!-- <img src="static/images/pretrain.png" alt="MY ALT TEXT"/> -->
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Experimental Results</h2>
          <div class="item">
              <h3 class="title is-4" style="margin-bottom: 20px;">Depth Estimation</h3>
              <div class="column is-center has-text-centered">
                  <img src="./static/images/comparison.png"
                       class="interpolation-image"
                       alt="Interpolate start reference image."
                       style="margin-bottom: 30px;"/>
              </div>

              <h3 class="title is-4" style="margin-top: 40px; margin-bottom: 20px;">Semantic Segmentation</h3>
              <div class="column is-center has-text-centered">
                  <img src="./static/images/seg_comparison.png"
                       class="interpolation-image"
                       alt="Interpolate start reference image."
                       style="width: auto; height: 350px;"
                  />
              </div>
          </div>

      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    @inproceedings{lin2025tide,
          title={A Unified Image-Dense Annotation Generation Model for Underwater Scenes},
          author={Lin, Hongkai and Liang, Dingkang and Qi, Zhenghao and Bai, Xiang},
          booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
          year={2025},
    }
    </code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <small><p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p></small>
          <small><p>
            We sincerely appreciate Nerfies authors <a href="https://github.com/nerfies/nerfies.github.io"> for their awesome templates.
          </p></small>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>

</html>